import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import joblib


# Ruta del dataset
file_path = f'../data/processed/forest_fires_prepared_df.csv'

# Cargar el dataset
data = pd.read_csv(file_path)


# Copiar los datos para evitar modificar el original
processed_data = data.copy()


# Codificar 'month' y 'day'
label_encoder_month = LabelEncoder()
label_encoder_day = LabelEncoder()
processed_data['month'] = label_encoder_month.fit_transform(processed_data['month'])
processed_data['day'] = label_encoder_day.fit_transform(processed_data['day'])


# Aplicar transformación logarítmica a 'area'
processed_data['area'] = np.log(processed_data['area'] + 1)


# Estandarizar características numéricas
scaler = StandardScaler()
numerical_features = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']
processed_data[numerical_features] = scaler.fit_transform(processed_data[numerical_features])


# Dividir los datos en características y variable objetivo
X = processed_data.drop(columns=['area'])
y = processed_data['area']


# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Guardar los datos procesados en archivos CSV
file_path = f'../data/processed'

X_train.to_csv(f'{file_path}/X_train_processed.csv', index=False)
X_test.to_csv(f'{file_path}/X_test_processed.csv', index=False)
y_train.to_csv(f'{file_path}/y_train_processed.csv', index=False)
y_test.to_csv(f'{file_path}/y_test_processed.csv', index=False)


# Guardar el dataset final procesado
processed_data.to_csv(f'{file_path}/forest_fires_processed_df.csv', index=False)



