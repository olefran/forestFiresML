{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "\n",
    "#Defining dataset\n",
    "\n",
    "dataset_ = fetch_ucirepo(id=162) # 162 for forest fires\n",
    "X = dataset_.data.features \n",
    "y = dataset_.data.targets\n",
    "data_ = pd.concat([X, y], axis = 1)\n",
    "\n",
    "# Creating the classes\n",
    "\n",
    "class DataExplorer:\n",
    "    @staticmethod\n",
    "    def explore_data(data_):\n",
    "        print(data_.head().T)\n",
    "        print(data_.describe())\n",
    "        print(data_.info())\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_histograms(data_):\n",
    "        data_.hist(bins=15, figsize=(15, 10))\n",
    "        plt.show()\n",
    "\n",
    "    def data_exp_n_prep(data_):\n",
    "        print(\"\\nValores nulos por columna:\")\n",
    "        print(data_.isnull().sum())\n",
    "\n",
    "class FF_model:\n",
    "    def __init__(self, data_):\n",
    "        self.data_ = data_\n",
    "\n",
    "    def data_prep(self):\n",
    "        \n",
    "        data = data_.dropna()\n",
    "\n",
    "        print(f\"\\nNúmero de filas duplicadas: {data.duplicated().sum()}\")\n",
    "        data = data.drop_duplicates()\n",
    "        print(f\"Número de filas después de eliminar duplicados: {data.shape[0]}\")\n",
    "\n",
    "        Q1 = data['area'].quantile(0.25)\n",
    "        Q3 = data['area'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        data_filtered = data[(data['area'] >= lower_bound) & (data['area'] <= upper_bound)]\n",
    "        print(f\"Cantidad de datos después de eliminar outliers: {data_filtered.shape[0]}\")\n",
    "\n",
    "        data_filtered['log_area'] = np.log1p(data_filtered['area'])\n",
    "\n",
    "        data_filtered.to_csv(f'../data/processed/{\"forest_fires_prepared_df.csv\"}', index=False)\n",
    "\n",
    "    def data_processing(self):\n",
    "\n",
    "        processed_data = pd.read_csv(f'../data/processed/{\"forest_fires_prepared_df.csv\"}')\n",
    "\n",
    "        label_encoder_month = LabelEncoder()\n",
    "        label_encoder_day = LabelEncoder()\n",
    "        processed_data['month'] = label_encoder_month.fit_transform(processed_data['month'])\n",
    "        processed_data['day'] = label_encoder_day.fit_transform(processed_data['day'])\n",
    "\n",
    "        processed_data['area'] = np.log(processed_data['area'] + 1)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        numerical_features = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']\n",
    "        processed_data[numerical_features] = scaler.fit_transform(processed_data[numerical_features])\n",
    "\n",
    "        X = processed_data.drop(columns=['area'])\n",
    "        y = processed_data['area']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        file_path = f'../data/processed'\n",
    "\n",
    "        X_train.to_csv(f'{file_path}/X_train_processed.csv', index=False)\n",
    "        X_test.to_csv(f'{file_path}/X_test_processed.csv', index=False)\n",
    "        y_train.to_csv(f'{file_path}/y_train_processed.csv', index=False)\n",
    "        y_test.to_csv(f'{file_path}/y_test_processed.csv', index=False)\n",
    "\n",
    "        processed_data.to_csv(f'{file_path}/forest_fires_processed_df.csv', index=False)\n",
    "    \n",
    "    def model_creation(self):\n",
    "\n",
    "        X_train = pd.read_csv(f'{file_path}/X_train_processed.csv')\n",
    "        X_test = pd.read_csv(f'{file_path}/X_test_processed.csv')\n",
    "        y_train = pd.read_csv(f'{file_path}/y_train_processed.csv')\n",
    "        y_test = pd.read_csv(f'{file_path}/y_test_processed.csv')\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        linear_model = LinearRegression()\n",
    "        linear_model.fit(X_train, y_train)\n",
    "        y_pred_lr = linear_model.predict(X_test)\n",
    "        rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "        r2_lr = r2_score(y_test, y_pred_lr)\n",
    "        results[\"Regresión Lineal\"] = {'RMSE': rmse_lr, 'R²': r2_lr}\n",
    "\n",
    "        linear_model = LinearRegression()\n",
    "        linear_model.fit(X_train, y_train)\n",
    "        y_pred_lr = linear_model.predict(X_test)\n",
    "        rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "        r2_lr = r2_score(y_test, y_pred_lr)\n",
    "        results[\"Regresión Lineal\"] = {'RMSE': rmse_lr, 'R²': r2_lr}\n",
    "\n",
    "        rf_model = RandomForestRegressor(random_state=42)\n",
    "        rf_model.fit(X_train, y_train['area'])\n",
    "        y_pred_rf = rf_model.predict(X_test)\n",
    "        rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "        r2_rf = r2_score(y_test, y_pred_rf)\n",
    "        results[\"Random Forest\"] = {'RMSE': rmse_rf, 'R²': r2_rf}\n",
    "\n",
    "        svm_model = SVR(kernel='rbf')\n",
    "        svm_model.fit(X_train, y_train['area'])\n",
    "        y_pred_svm = svm_model.predict(X_test)\n",
    "        rmse_svm = np.sqrt(mean_squared_error(y_test, y_pred_svm))\n",
    "        r2_svm = r2_score(y_test, y_pred_svm)\n",
    "        results[\"SVM\"] = {'RMSE': rmse_svm, 'R²': r2_svm}\n",
    "\n",
    "        gb_model = GradientBoostingRegressor(random_state=42)\n",
    "        gb_model.fit(X_train, y_train['area'])\n",
    "        y_pred_gb = gb_model.predict(X_test)\n",
    "        rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "        r2_gb = r2_score(y_test, y_pred_gb)\n",
    "        results[\"Gradient Boosting\"] = {'RMSE': rmse_gb, 'R²': r2_gb}\n",
    "\n",
    "        print(\"\\nResultados de Evaluación:\")\n",
    "        for model_name, metrics in results.items():\n",
    "            print(f\"{model_name}:\")\n",
    "            print(f\"  RMSE: {metrics['RMSE']}\")\n",
    "            print(f\"  R²: {metrics['R²']}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "        model_names = list(results.keys())\n",
    "        rmse_values = [metrics['RMSE'] for metrics in results.values()]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(model_names, rmse_values, color='skyblue')\n",
    "        plt.xlabel('RMSE')\n",
    "        plt.title('Comparación de RMSE entre Modelos')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f198b6d72d4c045ba146bb9016fd0f926a090762a310083c3532c3e3deb5f0ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
